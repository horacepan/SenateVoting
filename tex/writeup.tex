\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2016}

\usepackage[final]{nips_2016}
\usepackage{adjustbox}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2016}

\usepackage{amsmath,amsthm,amssymb}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\title{Learning Senate Graph Structure}

\author{
  Horace Pan\\
  University of Chicago\\
  \texttt{hopan@uchicago.edu} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
We attempt to fit a graphical model to Senate roll call data from the 114th Congress(2015-2016) to
reveal information about Senators voting tendencies. We apply neighborhood selection and the graphical
lasso to learn the edge set of this graphical model.
\end{abstract}

\section{Problem Setup}
Given $n$ samples of a $p$-dimensional multivariate Gaussian random variable $\mathbf{X} = (X_1, X_2, ..., X_p) \sim \mathcal{N}(\mu, \Sigma)$,
we want to learn the conditional independencies of the distribution. As we've seen in class, this can be
be represented with a graphical model, $\mathcal{G} = (V, E)$, where our vertex set is $V= \{1, 2, ..., p\}$ and our edge set
contains the edge $(i, j)$ if and only if $X_i$ is conditionally dependent on $X_j$ given the remaining variables. Every pair that is
not in our edge set are conditionally independent given the remaining variables. For Senate roll call data, the $p$-dimensional random variables correspond to 
$100$-dimensional vector $\in \{+1, -1\}^p$. Each sample from this distribution corresponds to how the senators voted on a given bill. Learning the edge set or the sparsity pattern of a precision matrix is a well studied problem and many methods have been proposed over the years to solve it. In particular, we will discuss Neighborhood Selection and the Graph Lasso.

\section{Neighborhood Selection}
The idea of Neighborhood Selection is that the value of a single node 
should be dependent on only its neighbors. So, if we regress a single variable $X_i$ on the remainng
variables, we get the following coefficient vectors for $i=1, ..., p$: 
$$\Theta^{(i)} = \underset{\Theta: \Theta_i = 0}{argmin} || \mathbf{X}_{:,i} - X \Theta||_2^2 + \lambda ||\Theta||_1$$
Slightly deviating from the notation earlier, $\mathbf{X} \in \mathbb{R}^{n \times p}$, where $n$ is the number of samples and $p$ is the dimension of our random variable. $\mathbb{X}_{:, i}$ denotes the $i$th column of our data. The support of each coefficient vector can then be used to construct our edge set - the neighbors of vertice $i$ are exactly the $j$ indices where $\Theta_j^{(i)} \not = 0$. 
The Lasso penalty is used to encourage sparsity in our graphical model; having too many edges makes the graphical model less interpretable. 
Concretely, if we had a graphical model where all Republican senators clustered together, this would not tell us anything about their voting patterns(unless it were actually true that all Republican senators voted the same way every time).

\section{Graphical Lasso}
It is commonly known that the precision matrix(or the inverse covariance matrix) is informative of the
edge set of our graphical model. $\Sigma^{-1}_{i, j} = 0$ implies that variables $X_i$ and
$X_j$ are conditionally independent and that there is no edge between $X_i$ and $X_j$. So we can learn
the edge set of our graphical model by estimating the precision matrix. To do so, we solve for the precision
matrix that gives us the maximum log likelihood of our data. Let $\Theta = \Sigma^{-1}$,  $\mathbf{X}_i$ denotes the $ith$ sample, and $S$ is our empirical covariance: $$S = \sum_{i=1}^n (\mathbf{X}_i - \mu)(\mathbf{X}_i - \mu)^T$$
then, we want $\Theta$ to be: $$\Theta = argmax \log \det \Theta - tr(S \Theta) - \lambda ||\theta||_1$$
\begin{proof}
\begin{flalign}
P(\mathbf{X}|\mu) &= \frac{1}{(2\pi)^{n/2} \det \Sigma^\frac{1}{2}} \exp -\frac{1}{2} (\mathbf{X} - \mu)^T \Sigma^{-1} (\mathbf{X}- \mu) \\
&= \frac{\det \Theta^{\frac{1}{2}}}{(2\pi)^{n/2}} \exp -\frac{1}{2} (\mathbf{X} - \mu)^T \Theta (\mathbf{X}- \mu) \\
&= \frac{\det \Theta^{\frac{1}{2}}}{(2\pi)^{n/2}} \exp -\frac{1}{2} (X - \mu)^T \Theta (X- \mu) \\
\log P(\mathbf{X}_1, \mathbf{X}_2, ..., \mathbf{X}_n | \mu) j
&= \frac{n}{2} \log \det \Theta - \frac{1}{2} \sum_{i=1}^n (\mathbf{X}_i - \mu)^T \Theta (\mathbf{X}_i - \mu) - \text{a constant}\\
&\propto \det(\Theta) - \frac{1}{n} tr(\sum_{i=1}^n(\mathbf{X}_i - \mu)^T\Theta (\mathbf{X}_i - \mu) )\\
&= \det(\Theta) - \frac{1}{n} tr(\sum_{i=1}^n(\Theta \mathbf{X}_i - \mu)^T (\mathbf{X}_i - \mu) )\\
&= \det(\Theta) - \frac{1}{n} tr(\sum_{i=1}^n(\mathbf{X}_i - \mu)^T\Theta (\mathbf{X}_i - \mu)) \\
&= \det(\Theta) - \frac{1}{n} tr(\sum_{i=1}^n(\Theta \mathbf{X}_i - \mu)(\mathbf{X}_i - \mu)^T) \\
&= \det(\Theta) - \frac{1}{n} tr(\sum_{i=1}^n(\mathbf{X}_i - \mu)(\mathbf{X}_i - \mu)^T \Theta)\\
&= (\det(\Theta) - tr(S\Theta))
\end{flalign}
Thus, maximizing the LASSO penalized log likelihood is the same as maximizing:
$$ \det(\Theta) - tr(S \Theta) - \lambda ||\Theta||_1 $$
\end{proof}
The term in the summation in (4) is just a scalar so we can take the trace of it without changing anything. Then, we use the fact that $tr(AB) = tr(BA)$ repeatedly to get from line (4) to (10).

Banerjee, et. al. 2008 describes a block coordinate descent algorithm to solve this minimization problem. For my experiments, I attempted to use the GraphLasso method implemented in the scikit-learn Python library instead of writing it from scratch due to the fickle nature of the block coordinate convergence but could not successfully run it because the empirical covariance matrix from the voting data was too ill conditioned for convergence.

\section{Senate roll call data}
I scraped Senate roll call data from 2015-2016 from the 114th Congress off of \href{https://www.govtrack.us/}{https://www.govtrack.us/}. This included 339 votes
in 2015 and 88 votes(as of June 3rd) in 2016. Roll call date included the votes(Yes, No, Not present) for each senator, time of vote, the bill or amendment that
the vote pertained to, and the subject area of the vote(IE: Taxation, healthcare, etc).
Since we dealt with the "Not present" votes by setting those votes to "No/Nay" because a Not present vote is effectively a "No/Nay" vote for the purpose of passing a bill. I also tried using Senator's party's majority vote to fill in missing votes, but there was little discernable difference in the resulting graphs in both cases so I stuck with converting "Not present" votes to "No/Nay" votes.

\subsection{Refining bills by topic}
We implicitly assumed that all Senator voting tendencies are uniform across all bills. However, it is not to difficult to imagine cases where this is not true. Senators from midwest states are
highly unlikely to vote against any bill that might reduce farm subsidies, regardless of what their party might vote.
It is natural to expect that voting dependencies would vary by the subject of each bill. So, we attempt to cluster bills by their topics and then try to learn a separate graphical model for each subset of bills. We applied Latent Dirichlet Allocation on the bill summaries of each bill voted on. See table \ref{tbl: lda} for the resulting topics and some of the top words for each topic.

\begin{table*}[]
\centering
\vspace{-10pt}
\caption{\label{tbl: lda}Topics and top words computed with LDA}
\begin{tabular}{c c c c c}
\hline
Energy      & Budget    & Military/National Defense & Education & Health \\
\hline
energy      & deficit   & funds                     & school           & sec \\
water       & raising   & dod                       & district         & health \\
doe         & spending  & defense                   & requirements     & 2017 \\
efficiency  & fy2016    & security                  & esea             & medicaid \\
heaters     & reserve   & national                  & charter          & payments \\
demand      & increase  & program                   & student          & medical  \\
\hline
\end{tabular}
\end{table*}
I did not realize that I could actually scrape bills' subject areas until after doing this LDA(since the govtrack.us site didn't have the subject areas through its website, but did expose it through its bulk data api). Table \ref{tbl: topics} shows the breakdown of the topics.
\begin{table*}[]
\centering
\vspace{-10pt}
\caption{\label{tbl: topics}Top Subject Areas Count(given by govtrack.us)}
\begin{tabular}{c c c c c}
\hline
Topic      & Bill Count    \\
\hline
Economics and Public Finance              & 123\\ 
Energy                                    &  66\\
Nomination                                &  42\\
Armed Forces and National Security        &  37\\
Health                                    &  29\\
Education                                 &  29\\
Crime and Law Enforcement                 &  25\\
Transportation and Public Works           &  16\\
Emergency Management                      &  11\\
Taxation                                  &  10\\
Government Operations and Politics        &   9\\
International Affairs                     &   7\\
Environmental Protection                  &   6\\
Labor and Employment                      &   4\\
Finance and Financial Sector              &   3\\
Immigration                               &   3\\
Foreign Trade and International Finance   &   3\\
Agriculture and Food                      &   2\\
Civil actions and liability               &   1\\
Law                                       &   1\\
\hline
Total                                     & 427\\
\hline
\end{tabular}
\end{table*}
The top topics given by LDA given by LDA seem to match the true topics reasonably well. LDA missed the nominations topic(also was not in the top 10), but I think this is because the bill summaries for Nominations votes were almost always only a sentence long(EG: "On the Nomination PN327: Paula Xinis, of Maryland, to be United States District Judge for the District of Maryland") where as bill summaries for clotures/passages/resolutions/etc mostly spanned multiple paragraphs. I applied neighborhood selection on Economics, Energy, and Armed Forces/National Security. The following figures show the resulting graphical models. For all of the graphs, I generated a graph using the Networkx python library with the resulting edge sets given by Neighborhood selection or Graphical Lasso and then exported a gexf file. To visualize the graphs, I used Gephi, an open source graph visualization software. In the visualizations, the distances betweenconnected components are irrelevant; only the edge sets matter.

\begin{figure} 
\caption{\label{fig: nbd55}All bills. Neighborhood Selection with $\lambda = 0.55$}
  \includegraphics[width=\textwidth]{nbd_55_all.png}
\end{figure}

\begin{figure} 
\caption{\label{fig: nbd75}All bills. Neighborhood Selection with $\lambda = 0.75$}
  \includegraphics[width=\textwidth]{nbd_75.png}
\end{figure}

\begin{figure} 
\caption{\label{fig: en55}Energy Related Bills only. Neighborhood Selection with $\lambda = 0.55$}
  \includegraphics[width=\textwidth]{energy_55.png}
\end{figure}

\begin{figure} 
\caption{\label{fig: ec55}Economics/Public Finance Related bills only Neighborhood Selection with $\lambda = 0.55$}
  \includegraphics[width=\textwidth]{econ_nbd_55.png}
\end{figure}
\begin{figure} 
\caption{\label{fig: mil55}Military related bills only. Neighborhood Selection with $\lambda = 0.55$}
  \includegraphics[width=\textwidth]{military.png}
\end{figure}

\begin{table}
\centering
\vspace{-10pt}
\caption{\label{tbl: topics}Proportion of Republicans and Democrats voting the same on various bill topics}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{c c c c c}
\hline
Bill Topic      & Proportion of Republicans voting the same & Proportion of Democrats voting the same    \\
\hline
Economics and Public Finance              & 87\% & 94\%\\ 
Energy                                    & 90\% & 93\%\\
Armed Forces and National Security        & 84\% & 87\%\\
Nomination                                & 83\% & 97\%\\
All bills                                 & 87\% & 93\%\\
\hline
\end{tabular}
\end{adjustbox}
\end{table}

\section{Findings}
Figure \ref{fig: nbd55} and \ref{fig: nbd75} show the result of neighbhood selection applied with $lambda$ values of $0.55$ and $0..75$ respectively. In figure 1 we can see that the republican party(red) has
more "rogue" senators who have no dependencies on other Republican senators. The Democrat party is more tightly clustered and only has 3 senators(Joe Manchin(WV), Bill Nelson(FL) and Heidi Heitkamp(ND)).  West Virginia and North Dakota are relatively conservative states that Mitt Romney carried in the 2012 election, Manchin and Heitkamp are not connected to other Democrats. I'm not sure what's going on with Bill Nelson though. Though a bit hard to see, Harry Reid is only incident on two other vertices/senators, which I found a bit surprising. On a second comb through the data, I discovered that Reid had missed 54 out of the 427 votes so that might account for this supposed lack of influence.
Mitch McConnell also only has two connections but he connects two clusters of Republicans: one cluster centered around John McCain and Roger Wicker and another centered around Tom Cotton.

In figure \ref{fig: nbd75}, after increasing the LASSO penalty, we see that there are almost no dependencies between Republican senators, but the Democrats are still clustered together. I suppose this shows that the Democratic party is more idealogically cohesive perhaps? The figures in table 3 also help support the claims of the Democratic party being less fractured.

Figure \ref{fig: en55} shows the graphical model using only Energy related bills. The graph paints a slightly different picture than figures 1 and 2. It seems the Republican party is mostly cohesive on this issue
and Democrats have two clusters of dependencies with senators on the fringes each influencing each other. The center of the Democrat cluster on the top is Senator Sherrod Brown of Ohio.

Figure \ref{fig: ec55} shows the graphical model using only economics and public finance related bills.

Figure \ref{fig: mil55} shows the graphical model on only military related bills. Here the Democratic senators have 4 mostly non intersecting clusters. Elizabeth Warren, on other bill topics, is almost always in
the main cluster of Democrats, but here she is not connected to anyone else. Also of note is that Chuck Schumer is in an isolated cluster, though he is usually connected to Harry Reid and Kristen Gillibrand(his fellow NY senator) on other bills topics.

It seems that on the big issues: energy, economics/public finance and military, the Republican party is in fact more cohesive than the Democrat party - though the Democrat party has multiple clusters, these spheres are usually connected to each other. The Republican party, outside of the main connected component for these three issues also have a number of isolated senators.

It seems that on the big issues: energy, economics/public finance and military, the Republican party is in fact more cohesive than the Democrat party - though the Democrat party has multiple clusters, these spheres are usually connected to each other. The Republican party, outside of the main connected component for these three issues also have a number of isolated senators.

Table 3 shows the proportion of Republicans and Democrats voting the same as other Senators in their party for the 4 most common bill topics. The proportions are fairly close except for nominations where Democrats agree 97\% of the time, where as Republicans agree only 83\% of the time - it makes sense that Democrats should almost always be in favor of any presidential nomination so the 97\% figure is not surprising.

\section{Further Exploration}
A natural next step would be to investigate how similarities in demographic and location might affect voting patterns and dependencies on senators. It would also probably be
informative to run this sort of visualization on members of congress. Neighborhood selection applied to senate roll call data seems most useful as a visualization/exploratory
data analysis tool for political pundits more than anything else. The visualized clusters from the generated graphs would certainly be more interpretable to someone who is more well versed in US politics than I am.

\section{Code and Data}
Code and data are hosted on my github repository at \href{https://www.github.com/horacepan/senatevoting}{https://www.github.com/horacepan/senatevoting}.

\section*{References}
References follow the acknowledgments. Use unnumbered first-level
heading for the references. Any choice of citation style is acceptable
as long as you are consistent. It is permissible to reduce the font
size to \verb+small+ (9 point) when listing the references. {\bf
  Remember that you can use a ninth page as long as it contains
  \emph{only} cited references.}
\medskip

\small

[1] Alexander, J.A.\ \& Mozer, M.C.\ (1995) Template-based algorithms
for connectionist rule extraction. In G.\ Tesauro, D.S.\ Touretzky and
T.K.\ Leen (eds.), {\it Advances in Neural Information Processing
  Systems 7}, pp.\ 609--616. Cambridge, MA: MIT Press.

[2] Bower, J.M.\ \& Beeman, D.\ (1995) {\it The Book of GENESIS:
  Exploring Realistic Neural Models with the GEneral NEural SImulation
  System.}  New York: TELOS/Springer--Verlag.

[3] Hasselmo, M.E., Schnell, E.\ \& Barkai, E.\ (1995) Dynamics of
learning and recall at excitatory recurrent synapses and cholinergic
modulation in rat hippocampal region CA3. {\it Journal of
  Neuroscience} {\bf 15}(7):5249-5262.

\end{document}
